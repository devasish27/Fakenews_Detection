{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e24a92fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48cd13a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DEVASISH\\anaconda3\\lib\\site-packages\\deeplake\\util\\check_latest_version.py:32: UserWarning: A newer version of deeplake (4.2.14) is available. It's recommended that you update to the latest version using `pip install -U deeplake`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\DEVASISH\\anaconda3\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening dataset in read-only mode as you don't have write permissions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\\"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This dataset can be visualized in Jupyter Notebook by ds.visualize() or at https://app.activeloop.ai/activeloop/liar-train\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hub://activeloop/liar-train loaded successfully.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening dataset in read-only mode as you don't have write permissions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This dataset can be visualized in Jupyter Notebook by ds.visualize() or at https://app.activeloop.ai/activeloop/liar-test\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hub://activeloop/liar-test loaded successfully.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening dataset in read-only mode as you don't have write permissions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "|"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This dataset can be visualized in Jupyter Notebook by ds.visualize() or at https://app.activeloop.ai/activeloop/liar-val\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hub://activeloop/liar-val loaded successfully.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " \r",
      "\r",
      "\r"
     ]
    }
   ],
   "source": [
    "import deeplake\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "import pandas as pd\n",
    "\n",
    "train_ds = deeplake.load(\"hub://activeloop/liar-train\")\n",
    "test_ds  = deeplake.load(\"hub://activeloop/liar-test\")\n",
    "val_ds   = deeplake.load(\"hub://activeloop/liar-val\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e480bca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_labels = [\"pants-fire\", \"false\", \"barely-true\"]\n",
    "true_labels = [\"half-true\", \"mostly-true\", \"true\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b42a563d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_label(label):\n",
    "    \n",
    "    if isinstance(label, bytes):\n",
    "        label = label.decode('utf-8')\n",
    "\n",
    "    if isinstance(label, torch.Tensor):\n",
    "        label = label.item()\n",
    "    return 0 if label in fake_labels else 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f0189f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LIARDataset(Dataset):\n",
    "    def __init__(self, deeplake_ds, tokenizer, max_length=128):\n",
    "        self.ds = deeplake_ds\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ds)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        statement = self.ds[idx]['statement'].numpy()\n",
    "        label = self.ds[idx]['label'].numpy()\n",
    "\n",
    "        # Handle bytes/numpy\n",
    "        if isinstance(statement, bytes):\n",
    "            statement = statement.decode('utf-8')\n",
    "        if isinstance(statement, torch.Tensor) or isinstance(statement, np.ndarray):\n",
    "            statement = statement.item()\n",
    "        label = map_label(label)\n",
    "\n",
    "        encodings = self.tokenizer(statement,\n",
    "                                   truncation=True,\n",
    "                                   padding='max_length',\n",
    "                                   max_length=self.max_length,\n",
    "                                   return_tensors='pt')\n",
    "        item = {key: val.squeeze(0) for key, val in encodings.items()}\n",
    "        item['labels'] = torch.tensor(label)\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04596347",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "train_dataset = LIARDataset(train_ds, tokenizer)\n",
    "val_dataset   = LIARDataset(val_ds, tokenizer)\n",
    "test_dataset  = LIARDataset(test_ds, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d57f0711",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e55f1355",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "comet_ml version 3.40.0 is installed, but version 3.43.2 or higher is required. Please update comet_ml to the latest version to enable Comet logging with pip install 'comet-ml>=3.43.2'.\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=2,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    logging_dir='./logs',\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6cb9463f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_small = torch.utils.data.Subset(train_dataset, range(500))  # first 500 samples\n",
    "val_dataset_small   = torch.utils.data.Subset(val_dataset, range(200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c004d4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 64  # instead of 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2ef39750",
   "metadata": {},
   "outputs": [],
   "source": [
    "per_device_train_batch_size=8\n",
    "per_device_eval_batch_size=8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a6eb6728",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8836e4e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c532dbc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "import torch\n",
    "\n",
    "device = \"cpu\"  # force CPU\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2).to(device)\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Example: tokenize a small subset\n",
    "texts = [\"Fake news example\", \"This is true news\"]\n",
    "labels = [0, 1]\n",
    "\n",
    "encodings = tokenizer(texts, truncation=True, padding=True, max_length=64, return_tensors=\"pt\")\n",
    "dataset = torch.utils.data.TensorDataset(encodings['input_ids'], encodings['attention_mask'], torch.tensor(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c065dd4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\devasish\\anaconda3\\lib\\site-packages (4.55.4)\n",
      "Requirement already satisfied: requests in c:\\users\\devasish\\anaconda3\\lib\\site-packages (from transformers) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\devasish\\anaconda3\\lib\\site-packages (from transformers) (0.21.4)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\devasish\\anaconda3\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in c:\\users\\devasish\\anaconda3\\lib\\site-packages (from transformers) (0.34.4)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\devasish\\anaconda3\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\devasish\\appdata\\roaming\\python\\python39\\site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\devasish\\anaconda3\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: filelock in c:\\users\\devasish\\anaconda3\\lib\\site-packages (from transformers) (3.3.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\devasish\\anaconda3\\lib\\site-packages (from transformers) (2025.7.34)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\devasish\\anaconda3\\lib\\site-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\devasish\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\devasish\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\devasish\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.4)\n",
      "Note: you may need to restart the kernel to use updated packages.Requirement already satisfied: idna<4,>=2.5 in c:\\users\\devasish\\anaconda3\\lib\\site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\devasish\\anaconda3\\lib\\site-packages (from requests->transformers) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\devasish\\anaconda3\\lib\\site-packages (from requests->transformers) (1.26.20)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\devasish\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\devasish\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\devasish\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\devasish\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\devasish\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\devasish\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\devasish\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "981bd879",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Subset\n",
    "\n",
    "# Take only a small portion for faster training\n",
    "small_train_dataset = Subset(train_dataset, range(min(2000, len(train_dataset))))\n",
    "small_val_dataset = Subset(val_dataset, range(min(500, len(val_dataset))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0908f476",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "comet_ml version 3.40.0 is installed, but version 3.43.2 or higher is required. Please update comet_ml to the latest version to enable Comet logging with pip install 'comet-ml>=3.43.2'.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [500/500 1:00:57, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.050200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.000300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=500, training_loss=0.005103312496328726, metrics={'train_runtime': 3664.2873, 'train_samples_per_second': 1.092, 'train_steps_per_second': 0.136, 'total_flos': 132467398656000.0, 'train_loss': 0.005103312496328726, 'epoch': 2.0})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import DistilBertForSequenceClassification, DistilBertTokenizer, Trainer, TrainingArguments\n",
    "\n",
    "# Load DistilBERT model + tokenizer\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=2)\n",
    "\n",
    "# Training arguments (compatible with older transformers)\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=2,              # just 1 epoch for faster run\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=50,\n",
    "    do_eval=False                    # disables evaluation each epoch\n",
    ")\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=small_train_dataset,\n",
    "    eval_dataset=small_val_dataset\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "eb16ed77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fake       0.00      0.00      0.00         0\n",
      "        True       1.00      1.00      1.00      1267\n",
      "\n",
      "    accuracy                           1.00      1267\n",
      "   macro avg       0.50      0.50      0.50      1267\n",
      "weighted avg       1.00      1.00      1.00      1267\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Ensure y_true is extracted properly (convert tensors to ints if needed)\n",
    "y_true = [int(map_label(sample['label'].numpy())) for sample in test_ds]\n",
    "\n",
    "print(\"Classification Report:\\n\")\n",
    "print(classification_report(\n",
    "    y_true,\n",
    "    y_pred,\n",
    "    labels=[0, 1],                         # explicitly tell sklearn both classes exist\n",
    "    target_names=['Fake', 'True'],\n",
    "    zero_division=0                        # avoid divide-by-zero errors\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0782c82f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DEVASISH\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:407: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(5,4))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Fake', 'True'], yticklabels=['Fake', 'True'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "15801704",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.Collecting textattack\n",
      "  Using cached textattack-0.3.10-py3-none-any.whl (445 kB)\n",
      "\n",
      "Requirement already satisfied: tqdm in c:\\users\\devasish\\anaconda3\\lib\\site-packages (from textattack) (4.67.1)\n",
      "Collecting bert-score>=0.3.5\n",
      "  Using cached bert_score-0.3.13-py3-none-any.whl (61 kB)\n",
      "Requirement already satisfied: more-itertools in c:\\users\\devasish\\anaconda3\\lib\\site-packages (from textattack) (10.7.0)\n",
      "Requirement already satisfied: pandas>=1.0.1 in c:\\users\\devasish\\anaconda3\\lib\\site-packages (from textattack) (1.3.4)\n",
      "Requirement already satisfied: torch!=1.8,>=1.7.0 in c:\\users\\devasish\\anaconda3\\lib\\site-packages (from textattack) (2.2.1)\n",
      "Collecting language-tool-python\n",
      "  Using cached language_tool_python-2.9.4-py3-none-any.whl (55 kB)\n",
      "Requirement already satisfied: transformers>=4.30.0 in c:\\users\\devasish\\anaconda3\\lib\\site-packages (from textattack) (4.55.4)\n",
      "Collecting lemminflect\n",
      "  Using cached lemminflect-0.2.3-py3-none-any.whl (769 kB)\n",
      "Collecting jieba\n",
      "  Using cached jieba-0.42.1-py3-none-any.whl\n",
      "Collecting editdistance\n",
      "  Using cached editdistance-0.8.1-cp39-cp39-win_amd64.whl (79 kB)\n",
      "Collecting OpenHowNet\n",
      "  Using cached OpenHowNet-2.0-py3-none-any.whl (18 kB)\n",
      "Collecting num2words\n",
      "  Using cached num2words-0.5.14-py3-none-any.whl (163 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\devasish\\anaconda3\\lib\\site-packages (from textattack) (3.3.1)\n",
      "Collecting word2number\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\devasish\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\devasish\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\devasish\\anaconda3\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\devasish\\anaconda3\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\devasish\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\devasish\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\devasish\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\devasish\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\devasish\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\devasish\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\devasish\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\devasish\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\devasish\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\devasish\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\devasish\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\devasish\\anaconda3\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Using cached word2number-1.1-py3-none-any.whl\n",
      "Collecting pinyin>=0.4.0\n",
      "  Using cached pinyin-0.4.0-py3-none-any.whl\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\devasish\\anaconda3\\lib\\site-packages (from textattack) (1.13.1)\n",
      "Requirement already satisfied: nltk in c:\\users\\devasish\\anaconda3\\lib\\site-packages (from textattack) (3.6.5)\n",
      "Collecting lru-dict\n",
      "  Using cached lru_dict-1.3.0-cp39-cp39-win_amd64.whl (13 kB)\n",
      "Collecting flair\n",
      "  Using cached flair-0.15.1-py3-none-any.whl (1.2 MB)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\devasish\\anaconda3\\lib\\site-packages (from textattack) (1.26.4)\n",
      "Collecting datasets>=2.4.0\n",
      "  Using cached datasets-4.0.0-py3-none-any.whl (494 kB)\n",
      "Collecting terminaltables\n",
      "  Using cached terminaltables-3.1.10-py2.py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\devasish\\anaconda3\\lib\\site-packages (from bert-score>=0.3.5->textattack) (3.4.3)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\devasish\\appdata\\roaming\\python\\python39\\site-packages (from bert-score>=0.3.5->textattack) (23.1)\n",
      "Requirement already satisfied: requests in c:\\users\\devasish\\anaconda3\\lib\\site-packages (from bert-score>=0.3.5->textattack) (2.32.5)\n",
      "Collecting multiprocess<0.70.17\n",
      "  Using cached multiprocess-0.70.16-py39-none-any.whl (133 kB)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in c:\\users\\devasish\\anaconda3\\lib\\site-packages (from datasets>=2.4.0->textattack) (0.34.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\devasish\\anaconda3\\lib\\site-packages (from datasets>=2.4.0->textattack) (21.0.0)\n",
      "Requirement already satisfied: fsspec[http]<=2025.3.0,>=2023.1.0 in c:\\users\\devasish\\anaconda3\\lib\\site-packages (from datasets>=2.4.0->textattack) (2025.3.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\devasish\\anaconda3\\lib\\site-packages (from datasets>=2.4.0->textattack) (6.0)\n",
      "Collecting dill<0.3.9,>=0.3.0\n",
      "  Using cached dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Requirement already satisfied: xxhash in c:\\users\\devasish\\anaconda3\\lib\\site-packages (from datasets>=2.4.0->textattack) (3.5.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\devasish\\anaconda3\\lib\\site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.4.0->textattack) (3.12.15)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\devasish\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.4.0->textattack) (0.3.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\devasish\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.4.0->textattack) (1.7.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\devasish\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.4.0->textattack) (2.6.1)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in c:\\users\\devasish\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.4.0->textattack) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\devasish\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.4.0->textattack) (24.2.0)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\devasish\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.4.0->textattack) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\devasish\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.4.0->textattack) (6.6.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\devasish\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.4.0->textattack) (1.20.1)\n",
      "Requirement already satisfied: typing-extensions>=4.2 in c:\\users\\devasish\\anaconda3\\lib\\site-packages (from aiosignal>=1.4.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.4.0->textattack) (4.15.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\devasish\\anaconda3\\lib\\site-packages (from pandas>=1.0.1->textattack) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\devasish\\anaconda3\\lib\\site-packages (from pandas>=1.0.1->textattack) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\devasish\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7.3->pandas>=1.0.1->textattack) (1.16.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\devasish\\anaconda3\\lib\\site-packages (from requests->bert-score>=0.3.5->textattack) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\devasish\\anaconda3\\lib\\site-packages (from requests->bert-score>=0.3.5->textattack) (2021.10.8)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\devasish\\anaconda3\\lib\\site-packages (from requests->bert-score>=0.3.5->textattack) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\devasish\\anaconda3\\lib\\site-packages (from requests->bert-score>=0.3.5->textattack) (2.10)\n",
      "Requirement already satisfied: sympy in c:\\users\\devasish\\anaconda3\\lib\\site-packages (from torch!=1.8,>=1.7.0->textattack) (1.9)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\devasish\\anaconda3\\lib\\site-packages (from torch!=1.8,>=1.7.0->textattack) (2.11.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\devasish\\anaconda3\\lib\\site-packages (from torch!=1.8,>=1.7.0->textattack) (2.6.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\devasish\\anaconda3\\lib\\site-packages (from tqdm->textattack) (0.4.4)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\devasish\\anaconda3\\lib\\site-packages (from transformers>=4.30.0->textattack) (0.21.4)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\devasish\\anaconda3\\lib\\site-packages (from transformers>=4.30.0->textattack) (0.6.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\devasish\\anaconda3\\lib\\site-packages (from transformers>=4.30.0->textattack) (2025.7.34)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\devasish\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\devasish\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\devasish\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\devasish\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\devasish\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\devasish\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\devasish\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\devasish\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\devasish\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\devasish\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\devasish\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\devasish\\anaconda3\\lib\\site-packages)\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pathos 0.3.4 requires dill>=0.4.0, but you have dill 0.3.8 which is incompatible.\n",
      "pathos 0.3.4 requires multiprocess>=0.70.18, but you have multiprocess 0.70.16 which is incompatible.\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\devasish\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\devasish\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\devasish\\anaconda3\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lxml>=4.8.0 in c:\\users\\devasish\\anaconda3\\lib\\site-packages (from flair->textattack) (6.0.1)\n",
      "Requirement already satisfied: wikipedia-api>=0.5.7 in c:\\users\\devasish\\anaconda3\\lib\\site-packages (from flair->textattack) (0.8.1)\n",
      "Requirement already satisfied: boto3>=1.20.27 in c:\\users\\devasish\\anaconda3\\lib\\site-packages (from flair->textattack) (1.40.18)\n",
      "Collecting ftfy>=6.1.0\n",
      "  Using cached ftfy-6.3.1-py3-none-any.whl (44 kB)\n",
      "Collecting gdown>=4.4.0\n",
      "  Using cached gdown-5.2.0-py3-none-any.whl (18 kB)\n",
      "Collecting langdetect>=1.0.9\n",
      "  Using cached langdetect-1.0.9-py3-none-any.whl\n",
      "Requirement already satisfied: tabulate>=0.8.10 in c:\\users\\devasish\\anaconda3\\lib\\site-packages (from flair->textattack) (0.9.0)\n",
      "Collecting deprecated>=1.2.13\n",
      "  Using cached Deprecated-1.2.18-py2.py3-none-any.whl (10.0 kB)\n",
      "Collecting bioc<3.0.0,>=2.0.0\n",
      "  Using cached bioc-2.1-py3-none-any.whl (33 kB)\n",
      "Requirement already satisfied: segtok>=1.5.11 in c:\\users\\devasish\\anaconda3\\lib\\site-packages (from flair->textattack) (1.5.11)\n",
      "Requirement already satisfied: pptree>=3.1 in c:\\users\\devasish\\anaconda3\\lib\\site-packages (from flair->textattack) (3.1)\n",
      "Requirement already satisfied: transformer-smaller-training-vocab>=0.2.3 in c:\\users\\devasish\\anaconda3\\lib\\site-packages (from flair->textattack) (0.4.2)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in c:\\users\\devasish\\anaconda3\\lib\\site-packages (from flair->textattack) (1.6.1)\n",
      "Requirement already satisfied: pytorch-revgrad>=0.2.0 in c:\\users\\devasish\\anaconda3\\lib\\site-packages (from flair->textattack) (0.2.0)\n",
      "Requirement already satisfied: sqlitedict>=2.0.0 in c:\\users\\devasish\\anaconda3\\lib\\site-packages (from flair->textattack) (2.1.0)\n",
      "Requirement already satisfied: mpld3>=0.3 in c:\\users\\devasish\\anaconda3\\lib\\site-packages (from flair->textattack) (0.5.11)\n",
      "Collecting conllu<5.0.0,>=4.0\n",
      "  Using cached conllu-4.5.3-py2.py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: docopt in c:\\users\\devasish\\anaconda3\\lib\\site-packages (from bioc<3.0.0,>=2.0.0->flair->textattack) (0.6.2)\n",
      "Requirement already satisfied: intervaltree in c:\\users\\devasish\\anaconda3\\lib\\site-packages (from bioc<3.0.0,>=2.0.0->flair->textattack) (3.1.0)\n",
      "Requirement already satisfied: jsonlines>=1.2.0 in c:\\users\\devasish\\anaconda3\\lib\\site-packages (from bioc<3.0.0,>=2.0.0->flair->textattack) (4.0.0)\n",
      "Requirement already satisfied: s3transfer<0.14.0,>=0.13.0 in c:\\users\\devasish\\anaconda3\\lib\\site-packages (from boto3>=1.20.27->flair->textattack) (0.13.1)\n",
      "Requirement already satisfied: botocore<1.41.0,>=1.40.18 in c:\\users\\devasish\\anaconda3\\lib\\site-packages (from boto3>=1.20.27->flair->textattack) (1.40.18)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in c:\\users\\devasish\\anaconda3\\lib\\site-packages (from boto3>=1.20.27->flair->textattack) (1.0.1)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in c:\\users\\devasish\\anaconda3\\lib\\site-packages (from deprecated>=1.2.13->flair->textattack) (1.12.1)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\devasish\\anaconda3\\lib\\site-packages (from ftfy>=6.1.0->flair->textattack) (0.2.5)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\devasish\\anaconda3\\lib\\site-packages (from gdown>=4.4.0->flair->textattack) (4.10.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\devasish\\anaconda3\\lib\\site-packages (from matplotlib->bert-score>=0.3.5->textattack) (0.10.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\devasish\\anaconda3\\lib\\site-packages (from matplotlib->bert-score>=0.3.5->textattack) (3.0.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\devasish\\anaconda3\\lib\\site-packages (from matplotlib->bert-score>=0.3.5->textattack) (10.4.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\devasish\\anaconda3\\lib\\site-packages (from matplotlib->bert-score>=0.3.5->textattack) (1.3.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\devasish\\anaconda3\\lib\\site-packages (from scikit-learn>=1.0.2->flair->textattack) (3.6.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\devasish\\anaconda3\\lib\\site-packages (from scikit-learn>=1.0.2->flair->textattack) (1.5.2)\n",
      "Requirement already satisfied: accelerate>=0.26.0 in c:\\users\\devasish\\anaconda3\\lib\\site-packages (from transformers>=4.30.0->textattack) (1.10.1)\n",
      "Requirement already satisfied: protobuf in c:\\users\\devasish\\anaconda3\\lib\\site-packages (from transformers>=4.30.0->textattack) (3.20.3)\n",
      "Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in c:\\users\\devasish\\anaconda3\\lib\\site-packages (from transformers>=4.30.0->textattack) (0.2.1)\n",
      "Requirement already satisfied: psutil in c:\\users\\devasish\\anaconda3\\lib\\site-packages (from accelerate>=0.26.0->transformers>=4.30.0->textattack) (5.8.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\devasish\\anaconda3\\lib\\site-packages (from beautifulsoup4->gdown>=4.4.0->flair->textattack) (2.2.1)\n",
      "Requirement already satisfied: sortedcontainers<3.0,>=2.0 in c:\\users\\devasish\\anaconda3\\lib\\site-packages (from intervaltree->bioc<3.0.0,>=2.0.0->flair->textattack) (2.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\devasish\\anaconda3\\lib\\site-packages (from jinja2->torch!=1.8,>=1.7.0->textattack) (1.1.1)\n",
      "Requirement already satisfied: toml in c:\\users\\devasish\\anaconda3\\lib\\site-packages (from language-tool-python->textattack) (0.10.2)\n",
      "Requirement already satisfied: click in c:\\users\\devasish\\anaconda3\\lib\\site-packages (from nltk->textattack) (8.0.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\devasish\\anaconda3\\lib\\site-packages (from OpenHowNet->textattack) (69.5.1)\n",
      "Collecting anytree\n",
      "  Using cached anytree-2.13.0-py3-none-any.whl (45 kB)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in c:\\users\\devasish\\anaconda3\\lib\\site-packages (from requests->bert-score>=0.3.5->textattack) (1.7.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\devasish\\anaconda3\\lib\\site-packages (from sympy->torch!=1.8,>=1.7.0->textattack) (1.2.1)\n",
      "Installing collected packages: dill, multiprocess, langdetect, gdown, ftfy, deprecated, conllu, bioc, anytree, word2number, terminaltables, pinyin, OpenHowNet, num2words, lru-dict, lemminflect, language-tool-python, jieba, flair, editdistance, datasets, bert-score, textattack\n",
      "  Attempting uninstall: dill\n",
      "    Found existing installation: dill 0.4.0\n",
      "    Uninstalling dill-0.4.0:\n",
      "      Successfully uninstalled dill-0.4.0\n",
      "  Attempting uninstall: multiprocess\n",
      "    Found existing installation: multiprocess 0.70.18\n",
      "    Uninstalling multiprocess-0.70.18:\n",
      "      Successfully uninstalled multiprocess-0.70.18\n",
      "Successfully installed OpenHowNet-2.0 anytree-2.13.0 bert-score-0.3.13 bioc-2.1 conllu-4.5.3 datasets-4.0.0 deprecated-1.2.18 dill-0.3.8 editdistance-0.8.1 flair-0.15.1 ftfy-6.3.1 gdown-5.2.0 jieba-0.42.1 langdetect-1.0.9 language-tool-python-2.9.4 lemminflect-0.2.3 lru-dict-1.3.0 multiprocess-0.70.16 num2words-0.5.14 pinyin-0.4.0 terminaltables-3.1.10 textattack-0.3.10 word2number-1.1\n"
     ]
    }
   ],
   "source": [
    "pip install textattack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650e4895",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4f231f0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "textattack: Unknown if model of class <class 'transformers.models.distilbert.modeling_distilbert.DistilBertForSequenceClassification'> compatible with goal function <class 'textattack.goal_functions.classification.untargeted_classification.UntargetedClassification'>.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'train_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19312/1638629064.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;31m# Prepare a small subset of your dataset for adversarial generation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0mtextattack_dataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'statement'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'binary_label'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[0madversarial_examples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19312/1638629064.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;31m# Prepare a small subset of your dataset for adversarial generation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0mtextattack_dataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'statement'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'binary_label'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[0madversarial_examples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_df' is not defined"
     ]
    }
   ],
   "source": [
    "from textattack.attack_recipes import TextFoolerJin2019\n",
    "from textattack.models.wrappers import HuggingFaceModelWrapper\n",
    "from textattack.datasets import Dataset\n",
    "\n",
    "from textattack.attack_recipes import BERTAttackLi2020\n",
    "\n",
    "\n",
    "\n",
    "# Wrap your trained model for TextAttack\n",
    "model_wrapper = HuggingFaceModelWrapper(model, tokenizer)\n",
    "\n",
    "# Select attack recipe\n",
    "attack = BERTAttackLi2020.build(model_wrapper)\n",
    "\n",
    "# Prepare a small subset of your dataset for adversarial generation\n",
    "textattack_dataset = Dataset([(train_df['statement'][i], int(train_df['binary_label'][i])) for i in range(200)])\n",
    "\n",
    "adversarial_examples = []\n",
    "\n",
    "for i, (text, label) in enumerate(textattack_dataset):\n",
    "    try:\n",
    "        result = attack.attack(text, label)\n",
    "        if result.perturbed_text:\n",
    "            adversarial_examples.append((result.perturbed_text, label))\n",
    "    except Exception as e:\n",
    "        continue\n",
    "\n",
    "print(f\"Generated {len(adversarial_examples)} adversarial examples.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437fbe5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "adv_df = pd.DataFrame(adversarial_examples, columns=[\"statement\", \"binary_label\"])\n",
    "augmented_train_df = pd.concat([train_df[['statement','binary_label']], adv_df]).reset_index(drop=True)\n",
    "\n",
    "# Tokenize augmented data\n",
    "train_encodings = tokenizer(list(augmented_train_df['statement']), truncation=True, padding=True, max_length=128)\n",
    "train_labels = list(augmented_train_df['binary_label'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e66a572",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    def __getitem__(self, idx):\n",
    "        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}, torch.tensor(self.labels[idx])\n",
    "\n",
    "train_dataset = CustomDataset(train_encodings, train_labels)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
